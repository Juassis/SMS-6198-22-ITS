---
title: "NBIS Report"
subtitle: '`r format(Sys.Date(),format="%d-%b-%Y")`'

output:
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
      print: false
    toc_depth: 4
    number_sections: true
    highlight: tango
    df_print: paged
    code_folding: "show"
    self_contained: true
    keep_md: false
    encoding: 'UTF-8'
    #css: "assets/report.css"
  pdf_document: default
---

<!-- ----------------------- Do not edit above this ----------------------- -->

```{r,echo=FALSE,include=FALSE}
# CUSTOM VARIABLES

# custom ggplot theme
theme_report_h <- function (base_size=12,base_family=NULL,colour="grey60") {
  theme_bw(base_size=base_size,base_family=base_family) %+replace%
    theme(
      panel.border=element_blank(),
      panel.grid.minor=element_blank(),
      panel.grid.major.x=element_blank(),
      legend.position="top",
      legend.direction="horizontal",
      legend.justification="center",
      strip.background=element_blank(),
      axis.ticks.y=element_blank(),
      axis.ticks.x=element_line(colour=colour),
      plot.caption=element_text(hjust=0,colour=colour,size=10),
      plot.title=element_text(colour=colour),
      plot.subtitle=element_text(colour=colour)
    )
}

# custom ggplot theme
theme_report <- theme_report_v <- function (base_size=12,base_family=NULL,colour="grey60") {
  theme_bw(base_size=base_size,base_family=base_family) %+replace%
    theme(
      panel.border=element_blank(),
      panel.grid.minor=element_blank(),
      panel.grid.major.x=element_blank(),
      legend.position="right",
      legend.direction="vertical",
      legend.justification="center",
      strip.background=element_blank(),
      axis.ticks.y=element_blank(),
      axis.ticks.x=element_line(colour=colour),
      plot.caption=element_text(hjust=0,colour=colour,size=10),
      plot.title=element_text(colour=colour),
      plot.subtitle=element_text(colour=colour)
    )
}

# custom ggplot theme
theme_simple_h <- function (base_size=12,base_family=NULL,colour="grey60") {
  theme_bw(base_size=base_size,base_family=base_family) %+replace%
    theme(
      panel.border=element_blank(),
      panel.grid=element_blank(),
      legend.justification="center",
      legend.position="top",
      legend.direction="horizontal",
      strip.background=element_blank(),
      axis.ticks=element_blank(),
      axis.text=element_blank(),
      axis.title=element_blank(),
      plot.caption=element_text(hjust=0,colour=colour,size=10),
      plot.title=element_text(colour=colour),
      plot.subtitle=element_text(colour=colour)
    )
}

# custom ggplot theme
theme_simple_v <- function (base_size=12,base_family=NULL,colour="grey60") {
  theme_bw(base_size=base_size,base_family=base_family) %+replace%
    theme(
      panel.border=element_blank(),
      panel.grid=element_blank(),
      legend.justification="center",
      legend.position="right",
      legend.direction="vertical",
      strip.background=element_blank(),
      axis.ticks=element_blank(),
      axis.text=element_blank(),
      axis.title=element_blank(),
      plot.caption=element_text(hjust=0,colour=colour,size=10),
      plot.title=element_text(colour=colour),
      plot.subtitle=element_text(colour=colour)
    )
}

#colours
col_sll_green <- "#95C11E"
col_sll_blue <- "#0093BD"
col_sll_orange <- "#EF7C00"
col_sll_green_light <- "#f4f8e8"
col_sll_blue_light <- "#e5f4f8"
col_sll_orange_light <- "#fdf1e5"

# project variables
rep_nbis_id <- "SMS_6198"
rep_report_version <- "1.0"
rep_request <- "Mona N. Högberg"
rep_request_email <- "mona.n.hogberg@slu.se"
rep_pi <- "Mona N. Högberg"
rep_pi_email <- "mona.n.hogberg@slu.se"
rep_org <- "SLU"
rep_nbis <- "Juliana Assis"
rep_nbis_email <- "juliana.assis@nbis.se"
```

<br>

::: boxy
__NBIS ID:__ `r rep_nbis_id`   
__Report Version:__ `r rep_report_version`  
__Request by:__ `r paste0(rep_request," (",rep_request_email,")")`  
__Principal Investigator:__ `r paste0(rep_pi," (",rep_pi_email,")")`   
__Organisation:__ `r rep_org`  
__NBIS Staff:__ `r paste0(rep_nbis," (",rep_nbis_email,")")`  
:::

<br>

# Setup

```{r message=FALSE, warning=FALSE}
## LIBRARIES
library("dada2")
library("devtools")
library("dplyr")
library("ggplot2")
library("microbiome")
library("phangorn") 
library("phyloseq") 
library("Rcpp")
library("reshape2")
library("tidyr")
library("vegan")
library("ShortRead")
library("Biostrings")
library("DECIPHER")
library("SensusR")
library("gplots")
library("gridExtra")
library("grid")
library("ggpubr")
library("reshape2")
library("reshape")
library("lulu")
library("ggrepel")
library("ggh4x")
library("RColorBrewer")
library("rITSx")
library("MicEco")
```

# Version
1.0 

* Support Request  
Request sent by the user:
Mona N. Högberg

# Data  
96 samples

* Type of data  

ITS amplicon

* Data location
rackham.uppmax.uu.se
/proj/snic2022-22-352

* Uppmax project ID
SNIC 2022/22-352

* NGI Project ID
P9723

* Database used
Unite

# Tools
NFCore-Ampliseq (Dada2)

```{r,echo=FALSE,include=FALSE}
load("/Users/juliana/Documents/NBIS/Projects/6198/R_Saving/SMS_Phyloseq_VF_ITSx_LULU_3652.RData")
```

```{r}
#Sample Info
head(sample_info_tab)
```

# Workflow

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Reading Files
path = "/Users/juliana/Documents/NBIS/Projects/6198/Data/Data2" #Data2
#Renaming
#_1.fq.gz
#R2.fastq.gz
fnFs = sort(list.files(path, pattern="_R1.fastq.gz"))
fnRs = sort(list.files(path, pattern="_R2.fastq.gz"))

sample.names = sapply(strsplit(fnFs, "_R"), `[`, 1)
show(sample.names)

fnFs = file.path(path, fnFs)
fnRs = file.path(path, fnRs)
```

```{r, echo=FALSE,include=FALSE, eval = FALSE}
filt_path = file.path(path, "filtered")
filtFs = file.path(filt_path, paste0(sample.names, "_F_filt.fastq"))
filtRs = file.path(filt_path, paste0(sample.names, "_R_filt.fastq"))
#Read Numbers : Rarefaction? Or only after filter. After length 250 (R1), 200 (R2) bad phred score (bellow 20)
#dev.off()
```

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE, warning=FALSE}

#Filter Sequences
plotQualityProfile(fnFs[1:12]) #96
plotQualityProfile(fnRs[1:12]) #96
```
```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Defining Primers
FWD <- "CTTGGTCATTTAGAGGAAGTAA"
REV <- "GCTGCGTTCTTCATCGATGC"  #small
#REV <- "TCCTCCGCTTATTGATATGC" #large
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Primer Orientation
allOrients <- function(primer) {
    # Create all orientations of the input sequence
    require(Biostrings)
    dna <- DNAString(primer)  # The Biostrings works w/ DNAString objects rather than character vectors
    orients <- c(Forward = dna, Complement = complement(dna), Reverse = reverse(dna), 
        RevComp = reverseComplement(dna))
    return(sapply(orients, toString))  # Convert back to character vector
}
FWD.orients <- allOrients(FWD)
REV.orients <- allOrients(REV)
FWD.orients
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Pre Filter
fnFs.filtN <- file.path(path, "filtN", basename(fnFs)) # Put N-filterd files in filtN/ subdirectory
fnRs.filtN <- file.path(path, "filtN", basename(fnRs))
filterAndTrim(fnFs, fnFs.filtN, fnRs, fnRs.filtN, maxN = 0, multithread = FALSE)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Checkin Primers
primerHits <- function(primer, fn) {
    # Counts number of reads in which the primer is found
    nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
    return(sum(nhits > 0))
}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.filtN[[1]]), 
    FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.filtN[[1]]), 
    REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.filtN[[1]]), 
    REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.filtN[[1]]))
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Removing Primers
cutadapt <- "/opt/homebrew/anaconda3/envs/cutadaptenv/bin/cutadapt" # CHANGE ME to the cutadapt path on your machine
system2(cutadapt, args = "--version") # Run shell commands from R
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Running cutdapt
path.cut <- file.path(path, "cutadapt")
if(!dir.exists(path.cut)) dir.create(path.cut)
fnFs.cut <- file.path(path.cut, basename(fnFs))
fnRs.cut <- file.path(path.cut, basename(fnRs))

FWD.RC <- dada2:::rc(FWD)
REV.RC <- dada2:::rc(REV)
# Trim FWD and the reverse-complement of REV off of R1 (forward reads)
R1.flags <- paste("-g", FWD, "-a", REV.RC) 
# Trim REV and the reverse-complement of FWD off of R2 (reverse reads)
R2.flags <- paste("-G", REV, "-A", FWD.RC) 
# Run Cutadapt
for(i in seq_along(fnFs)) {
  system2(cutadapt, args = c(R1.flags, R2.flags, "-n", 2, # -n 2 required to remove FWD and REV from reads
                             "-o", fnFs.cut[i], "-p", fnRs.cut[i], # output files
                             fnFs.filtN[i], fnRs.filtN[i])) # input files
}
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#sanity check
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut[[1]]), 
    FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.cut[[1]]), 
    REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.cut[[1]]), 
    REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut[[1]]))
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Data working 
path.cut = "/Users/juliana/Documents/NBIS/Projects/6198/Data/Data2/cutadapt"
# Forward and reverse fastq filenames have the format:
cutFs <- sort(list.files(path.cut, pattern = "_R1.fastq.gz"))
cutRs <- sort(list.files(path.cut, pattern = "_R2.fastq.gz"))
sample.names = sapply(strsplit(cutFs, "_R"), `[`, 1)
show(sample.names)
cutFs = file.path(path.cut, cutFs)
cutRs = file.path(path.cut, cutRs)
```

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE, warning=FALSE}
#Inspect read quality profiles
plotQualityProfile(cutFs[1:2])
```

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE, warning=FALSE}
plotQualityProfile(cutRs[1:2])
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
##Filter and trim
filtFs <- file.path(path.cut, "filtered", basename(cutFs))
filtRs <- file.path(path.cut, "filtered", basename(cutRs))
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
out <- filterAndTrim(cutFs, filtFs, cutRs, filtRs,
                     maxN = 0,maxEE = c(2, 2),
                     #truncLen=c(290,270), 
                     trimLeft = c(10,30),
                     truncQ = 2, minLen = 150,
                     rm.phix = TRUE, compress = TRUE,
                     multithread = TRUE)  # FALSE in M1 mac
head(out)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}

filt_path = "/Users/juliana/Documents/NBIS/Projects/6198/Data/Data2/cutadapt/filtered/"
filtFs = file.path(filt_path, paste0(sample.names, "_R1.fastq.gz"))
filtRs = file.path(filt_path, paste0(sample.names, "_R2.fastq.gz"))
#dev.off()
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
table(file.exists(filtFs)) 
table(file.exists(filtRs))

```

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE, warning=FALSE}
plotQualityProfile(filtFs[1:12])
plotQualityProfile(filtFs[1:12])
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
```

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE, warning=FALSE}
#Plot Error Rate
plotErrors(errF, nominalQ = TRUE)
plotErrors(errR, nominalQ = TRUE)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Dereplicate identical reads

derepFs <- derepFastq(filtFs, 
                      verbose = TRUE)

derepRs <- derepFastq(filtRs, 
                      verbose = TRUE)

# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Sample Inference
dadaFs <- dada(derepFs, 
               err = errF, 
               multithread = TRUE)

dadaRs <- dada(derepRs, 
               err = errR, 
               multithread = TRUE)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Merge paired reads
mergers <- mergePairs(dadaFs, 
                      derepFs, 
                      dadaRs, 
                      derepRs,
                      minOverlap = 16,
                      verbose=TRUE)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Construct Sequence Table
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Remove chimeras
seqtab.nochim <- removeBimeraDenovo(seqtab, 
                                    method="consensus", 
                                    multithread=TRUE, 
                                    verbose=TRUE)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Track reads through the pipeline
getN <- function(x) sum(getUniques(x))

track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, 
    getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", 
    "nonchim")
rownames(track) <- sample.names
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Distribution of sequence lengths:
table(nchar(getSequences(seqtab.nochim)))
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
table(nchar(getSequences(seqtab)))
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
hist(nchar(getSequences(seqtab.nochim)), main="Distribution of sequence lengths")
sum(seqtab.nochim)/sum(seqtab)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
head(track)
ma <- data.matrix(track)
barplot((track), main ="Track Reads", font.axis = 1, cex.axis=1, beside=TRUE, ylim=range(pretty(c(0,track))))
hist(seqComplexity(seqtab.nochim), 100)

```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Assign taxonomy
unite.ref <- "/Users/juliana/Documents/NBIS/Projects/6198/database/sh_general_release_10.05.2021/sh_general_release_dynamic_10.05.2021.fasta"  # CHANGE ME to location on your machine
taxa <- assignTaxonomy(seqtab.nochim, 
                       unite.ref, 
                       multithread = TRUE, 
                       tryRC = TRUE)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Inspecting the taxonomic assignments:
taxa.print <- taxa  # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#### giving seq headers more manageable names (ASV_1, ASV_2...)####
asv_seqs <- colnames(seqtab.nochim)
asv_headers <- vector(dim(seqtab.nochim)[2], mode="character")

for (i in 1:dim(seqtab.nochim)[2]) {
  asv_headers[i] <- paste(">ASV", i, sep="_")
}
asv_tax <- taxa
row.names(asv_tax) <- sub(">", "", asv_headers)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Construct phylogenetic tree
#Exporting seqs
seqs <- getSequences(taxa)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA)
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phang.align)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, 
                    model="GTR", 
                    optInv=TRUE, 
                    optGamma=TRUE,
                    rearrangement = "stochastic", 
                    control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)

```


```{r,echo=FALSE,include=FALSE, eval = FALSE}
####Phyloseq Object####
sample_info_tab <- read.table("/Users/juliana/Documents/NBIS/Projects/6198/Metadado/metadata.tsv", header=T, row.names=1,
                              check.names=F, sep="\t")

pseq <- phyloseq(tax_table(taxa), 
sample_data(sample_info_tab),
otu_table(seqtab.nochim, taxa_are_rows = FALSE),
seqs)#,
#phy_tree(fitGTR$tree)) Not addede
taxa_names(pseq) <- paste0("ASV", seq(ntaxa(pseq)))
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Exporting files
uniquesToFasta(getUniques(seqtab.nochim), "seqtab.nochim.fasta", ids=paste0("ASV", seq(length(getUniques(seqtab.nochim)))))
export <- t(seqtab.nochim)
rownames(export) = paste0("ASV", seq(length(getUniques(seqtab.nochim))))
export2 <- cbind('#ASVID' = rownames(export), export)
write.table(export, "otu_table.dada.nochim.txt", sep='\t', row.names=FALSE, quote=FALSE)
write.table(taxa, "taxa_table.dada.nochim.txt", sep='\t', row.names=FALSE, quote=FALSE)
write.table(track, "track.txt", sep='\t', row.names=FALSE, quote=FALSE)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Preparing for filter
physeq <- subset_taxa(pseq, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
ps0 <- physeq %>% subset_taxa( Family!= "mitochondria" | is.na(Family) & Class!="Chloroplast" | is.na(Class))
ps = filter_taxa(ps0, function(x) sum(x > 1) > (0.00*length(x)), TRUE)
```

```{bash,echo=FALSE,include=FALSE, eval = FALSE}
#Running ITSx
 ITSx -i seqtab.nochim.fasta -save_regions ITS1  -o ASVs.ITS1
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#ITSx Filter
#Prune taxa in phyloseq object based on ITSX results  
good_taxas <- read.table(file="/Users/juliana/Documents/NBIS/Projects/6198/Working/Lulu/ITS_Final/good_taxa_ITS1",sep="\t", header=FALSE, stringsAsFactors = FALSE) 
str(good_taxa)
good_taxa <- as.vector(unlist(good_taxas))
#Keep good taxa
#prune original ps object by bad taxa and rename to new ps object
ps
allTaxa2 <- taxa_names(ps)
allTaxa2 <- allTaxa2[(allTaxa2 %in% good_taxa)]
ps_ITS <- prune_taxa(allTaxa2, ps)
ps_ITS
```


```{bash,echo=FALSE,include=FALSE, eval = FALSE}
#LULU

#use local blast installed on computer through the Shell for the match steps
#if you haven't already done so, install local blast
#download from ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/

#open Tool/Shell from R Studio
#make blast database from your refseq file
#note that the path specification is needed if the working directory in the shell differs from the filepath
makeblastdb -in ASVs.ITS1.fasta -parse_seqids -dbtype nucl
#makeblastdb -in ASVs.ITS1.fasta -parse_seqids -dbtype nucl
#blast the ASVs against the database
blastn -db ASVs.ITS1.fasta -outfmt "6 qseqid sseqid pident" -out match_list.txt -qcov_hsp_perc 80 -perc_identity 84 -query seqtab.nochim.fasta

```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Preparing files to Lulu
# Extract abundance matrix from the phyloseq object
OTU1 = as(otu_table(ps_ITS), "matrix")
# transpose if necessary
if(taxa_are_rows(ps_ITS)){OTU1 <- t(OTU1)}
# Coerce to data.frame
OTUdf = as.data.frame(t(OTU1))
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Running Lulu
#read in match file from local blast
matchlist <- read.csv(file="/Users/juliana/Documents/NBIS/Projects/6198/Working/Lulu/LULU_Pos_ITS/match_list.txt",sep="\t", header=FALSE, stringsAsFactors = FALSE) 
str(matchlist)
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Checking results LULU
curated_result <- lulu(OTUdf, matchlist)
curated_result$curated_table
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#save lulu results
ASVtablelulu <- curated_result$curated_table
write.csv(ASVtablelulu, "/Users/juliana/Documents/NBIS/Projects/6198/Working/Lulu/LULU_Pos_ITS/ASVs_table_lulu.csv")

ASVlulu_discards <- curated_result$discarded_otus
write.csv(ASVlulu_discards, "/Users/juliana/Documents/NBIS/Projects/6198/Working/Lulu/LULU_Pos_ITS/filt_lulu_discards.csv")

ASVlulu_retained <- curated_result$curated_otus
write.csv(ASVlulu_retained, "/Users/juliana/Documents/NBIS/Projects/6198/Working/Lulu/LULU_Pos_ITS/filt_lulu_retained.csv")
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Lulu
#check counts curated and removed
curated_result$curated_count
curated_result$discarded_count
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Prune taxa in phyloseq object based on lulu results  
#Open discarded taxa file from lulu and convert from data.frame to vector
badTaxa_v <- ASVlulu_discards
#note: alternatively, could use the retained file to subset
#prune original ps object by bad taxa and rename to new ps object
ps_ITS
allTaxa <- taxa_names(ps_ITS)
allTaxa <- allTaxa[!(allTaxa %in% badTaxa_v)]
ps_lulu2 <- prune_taxa(allTaxa, ps_ITS)
ps_lulu2
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps_lulu2),
                 MARGIN = ifelse(taxa_are_rows(ps_lulu2), yes = 1, no = 2),
                 FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                      TotalAbundance = taxa_sums(ps_lulu2),
                      tax_table(ps_lulu2))
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})

```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
# Define phyla to filter
filterPhyla = c("p__Calcarisporiellomycota")
# Filter entries with unidentified Phylum.
ps1 = subset_taxa(ps_lulu2, !Phylum %in% filterPhyla)
ps1

```

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE, warning=FALSE}
# Subset to the remaining phyla
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps0),color=Phylum)) +
  # Include a guess for parameter
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) + geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Remove taxa not seen more than 2 times in at least 1% of the samples. This protects against an OTU with small mean & trivially large C.V.
ps2 = filter_taxa(ps1, function(x) sum(x > 2) > (0.01*length(x)), TRUE)
#  Count prevalence
length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
# Taxonomy table -> Renamed for plot
pseq_taxa_df = data.frame(ps2@tax_table, stringsAsFactors = F)
pseq_taxa_df[is.na(pseq_taxa_df)]<- 'Unknown'
pseq_taxa_df$Genus_name = pseq_taxa_df$Genus
pseq_taxa_df$Species_name = pseq_taxa_df$Species
# Replace NA Genus_name column values
pseq_taxa_df$Genus_name[which(pseq_taxa_df$Genus_name=='Unknown')] <- pseq_taxa_df$Family[which(pseq_taxa_df$Genus_name=='Unknown')]
pseq_taxa_df$Genus_name[which(pseq_taxa_df$Genus_name=='Unknown')] <- pseq_taxa_df$Order[which(pseq_taxa_df$Genus_name=='Unknown')]
pseq_taxa_df$Genus_name[which(pseq_taxa_df$Genus_name=='Unknown')] <- pseq_taxa_df$Class[which(pseq_taxa_df$Genus_name=='Unknown')]
pseq_taxa_df$Genus_name[which(pseq_taxa_df$Genus_name=='Unknown')] <- pseq_taxa_df$Phylum[which(pseq_taxa_df$Genus_name=='Unknown')]
pseq_taxa_df$Genus_name[which(pseq_taxa_df$Genus_name=='Unknown')] <- pseq_taxa_df$Kingdom[which(pseq_taxa_df$Genus_name=='Unknown')]
pseq_taxa_df$Genus_name[which(pseq_taxa_df$Genus_name=='Unknown')] <- 'Unknown'
# Generate a column with row number
pseq_taxa_df$ASV_id <- paste('[',seq.int(nrow(pseq_taxa_df)), ']', sep="")
pseq_taxa_df$ASV <- row.names(pseq_taxa_df)
# Replace Unknown Species_name
pseq_taxa_df$Species_name[which(pseq_taxa_df$Species_name=='Unknown')] <- ""
# Remove .
pseq_taxa_df$Species_name = stringr::str_replace(pseq_taxa_df$Species_name,"\\.", "/")
pseq_taxa_df$Species_name = stringr::str_replace(pseq_taxa_df$Species_name,"//", "/")
# If Species has more than 3 possible names, remove them
multiaffiliation_species<-which(lengths(strsplit(pseq_taxa_df$Species_name, "/"))>3)
pseq_taxa_df$Species_name[multiaffiliation_species] <- ""
# Combine Genus and Species name
pseq_taxa_df$Genus_Species_name = paste(pseq_taxa_df$Genus_name, pseq_taxa_df$Species_name)
pseq_taxa_df$Genus_Species_name <- trim.trailing(pseq_taxa_df$Genus_Species_name)
pseq_taxa_df$taxa_name = paste(pseq_taxa_df$Genus_Species_name, pseq_taxa_df$OTU_id)
pseq_taxa_df$taxa_name = stringr::str_replace_all(pseq_taxa_df$taxa_name,"\\_", " ")
pseq_taxa_df[, c('Genus_name', 'Species_name', 'Genus_Species_name')] = list(NULL)
tax_table(ps2) <- as.matrix(pseq_taxa_df)
#Exporting
write_phyloseq(ps2, type = "TAXONOMY")
write_phyloseq(ps2, type = "METADATA")
write_phyloseq(ps2, type = "OTU")
#saveRDS(ps2, "Final_met_Tax.rds") 
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#ps_new <- ps2: taxonomy fixed by hand
pseq <- ps_new
summarize_phyloseq(ps_new)
```

## Replicates Evaluation

Alpha Diversity Plot comparing the Replicates A and B.

Quality control analysis using matched samples from 3 different Transects: A, B and C of the experiment and replicates samples on each Ecotype.
Comparison of alpha diversity in technical replicates samples on all Ecotypes from each Transect. ASV richness and ASV Shannon diversity.
```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Def Colors
cols_Type <- c("A" = "#264D59", "B" = "#77A515")
cols_Ecotype <- c("Meadow" = "#D46C4E", "Spruce-Alder" = "#77A515", "Spruce" = "#264D59", "Alder" = "#43978D", "Pine" = "#d49c4e")
cols_Ecotype2 <- c("I", "II", "III","IV","V")
cols_Transect <- c("1" = "#264D59", "2" = "#77A515", "3" = "#D46C4E")
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Alpha Diversity
pseq <- ps_new
reads_sample <- readcount(pseq)
# check for first 5 samples
reads_sample[1:5]
sample_data(pseq)$Reads_Sample <- reads_sample
#
alpha_diversity <- estimate_richness(pseq,  measures = c("Shannon", "Observed"))
df <- data.frame(alpha_diversity, sample_data(pseq))
df$Transect <- factor(df$Transect, levels = c(1,2,3), labels = c("1","2", "3")) #Keep 1,2,3
df$Ecotype <- factor(df$Ecotype, levels = c("Meadow","Alder zone","Spruce-Alder", "Spruce","Pine"), labels = c("Meadow","Alder","Spruce-Alder", "Spruce","Pine"))
#df$Ecotype <- factor(df$Ecotype, levels = c("Meadow","Alder zone","Spruce-Alder", "Spruce","Pine"), labels = c("I", "II", "III","IV","V"))
```

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE}
##Plot measures
dose.labs <- c("Richness", "Shannon")
names(dose.labs) <- c("Observed", "Shannon")
#Scale
scales <- list(
  scale_y_continuous(limits = c(0,500)
            ))
#
options(ggrepel.max.overlaps = Inf)
df %>% 
  gather(key = metric, value = value, c("Observed", "Shannon")) %>%
  mutate(metric = factor(metric, levels = c("Observed", "Shannon"))) %>%
  ggplot(aes(x = Ecotype, y = value, color = Ecotype)) + #,shape = Type
  #geom_point(size=4) +
  #geom_boxplot(outlier.color = NA) +
  geom_violin(draw_quantiles = c( 0.5)) +
  geom_jitter(aes(color = Ecotype), height = 0, width = .2) +
  geom_text_repel(aes(label = Type), nudge_x = 0.06, size = 3.0, segment.alpha = 0.5) +
  labs(x = "", y = "") +
  theme_pubr(border = TRUE) +
  scale_colour_manual(values = cols_Ecotype) +
  theme(legend.position="top") +
  theme(legend.title = element_blank()) +
  facet_nested(metric~Transect, labeller=labeller(metric = dose.labs), scales = "free") +
  facetted_pos_scales(y = scales) 

```


```{r,echo=FALSE, eval = FALSE}
options(ggrepel.max.overlaps = Inf)
df %>% 
  gather(key = metric, value = value, c("Observed", "Shannon")) %>%
  mutate(metric = factor(metric, levels = c("Observed", "Shannon"))) %>%
  ggplot(aes(x = Ecotype, y = value, color = Ecotype, shape = Type,group=interaction(Transect, Ecotype))) +
  geom_point(size=4) + 
  #geom_line() +
  geom_text_repel(aes(label = Reads_Sample), nudge_x = 0.06, size = 3.0, segment.alpha = 0.5) +
  theme_pubr(border = TRUE) +
  theme(axis.text=element_text(size=14), 
        axis.text.x = element_text(size = 12, hjust = 0.5), 
        axis.title.y = element_text(size = 18),
        legend.text=element_text(size=8),
        legend.position = "none") +
  scale_colour_manual(values = cols_Ecotype) + 
  #scale_x_discrete(limits=c("Before", "After")) +
  labs(x = "", y = "") +
  theme(legend.position="top")+
  theme(legend.title = element_blank()) +
  facet_nested(metric~Transect, labeller=labeller(metric = dose.labs), scales = "free_y", space = "free_x") +
  facetted_pos_scales(y = scales)
```
* Beta Diversity Plot comparing the Replicates A and B.


```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE}
##Replicates
#Filter all samples with triplicates
Replicates <- subset_samples(pseq, Type =="A" | Type=="B")
#Relative Abundance
Replicates_R <- transform_sample_counts(Replicates, function(otu) otu/sum(otu))
jsd_dist<- sqrt(phyloseq::distance(Replicates_R, "jsd"))
pcoa_jsd <- ordinate(Replicates_R, method = "PCoA", distance = jsd_dist)
#
exptT = prune_taxa(names(sort(taxa_sums(Replicates_R), TRUE)), Replicates_R)
ordT2<- sqrt(phyloseq::distance(Replicates_R,Type = "samples", "jsd"))
pcoa=ordinate(Replicates_R, "PCoA", distance=ordT2)
#
a<-pcoa$values
b<-as.data.frame(pcoa$vectors)
samdf<-data.frame(unclass(Replicates_R@sam_data))
row.names(samdf)<-sample_names(Replicates_R)
#
distance_matrix<-matrix(jsd_dist)
distance_matrix<-as.matrix(jsd_dist)
distance_matrix<-as.data.frame(distance_matrix)
distance_matrix <-(distance_matrix)
#
compALL_T <-c("P9723_1025_S25_L001.P9723_1029_S29_L001","P9723_1033_S33_L001.P9723_1037_S37_L001","P9723_1041_S41_L001.P9723_1045_S45_L001","P9723_1001_S1_L001.P9723_1005_S5_L001","P9723_1009_S9_L001.P9723_1013_S13_L001","P9723_1017_S17_L001.P9723_1021_S21_L001","P9723_1002_S2_L001.P9723_1006_S6_L001","P9723_1010_S10_L001.P9723_1014_S14_L001","P9723_1018_S18_L001.P9723_1022_S22_L001","P9723_1073_S73_L001.P9723_1077_S77_L001","P9723_1081_S81_L001.P9723_1085_S85_L001","P9723_1089_S89_L001.P9723_1093_S93_L001","P9723_1049_S49_L001.P9723_1053_S53_L001","P9723_1065_S65_L001.P9723_1069_S69_L001","P9723_1050_S50_L001.P9723_1054_S54_L001","P9723_1058_S58_L001.P9723_1062_S62_L001","P9723_1066_S66_L001.P9723_1070_S70_L001","P9723_1026_S26_L001.P9723_1030_S30_L001","P9723_1034_S34_L001.P9723_1038_S38_L001","P9723_1042_S42_L001.P9723_1046_S46_L001","P9723_1027_S27_L001.P9723_1031_S31_L001","P9723_1035_S35_L001.P9723_1039_S39_L001","P9723_1043_S43_L001.P9723_1047_S47_L001","P9723_1011_S11_L001.P9723_1015_S15_L001","P9723_1019_S19_L001.P9723_1023_S23_L001","P9723_1074_S74_L001.P9723_1078_S78_L001","P9723_1082_S82_L001.P9723_1086_S86_L001","P9723_1090_S90_L001.P9723_1094_S94_L001","P9723_1075_S75_L001.P9723_1079_S79_L001","P9723_1083_S83_L001.P9723_1087_S87_L001","P9723_1091_S91_L001.P9723_1095_S95_L001","P9723_1051_S51_L001.P9723_1055_S55_L001","P9723_1059_S59_L001.P9723_1063_S63_L001","P9723_1067_S67_L001.P9723_1071_S71_L001","P9723_1052_S52_L001.P9723_1056_S56_L001","P9723_1060_S60_L001.P9723_1064_S64_L001","P9723_1068_S68_L001.P9723_1072_S72_L001","P9723_1028_S28_L001.P9723_1032_S32_L001","P9723_1036_S36_L001.P9723_1040_S40_L001","P9723_1044_S44_L001.P9723_1048_S48_L001","P9723_1012_S12_L001.P9723_1016_S16_L001","P9723_1020_S20_L001.P9723_1024_S24_L001")
#
distance_matrix$samples<-row.names(distance_matrix)
distance_matrix_melt<-melt.data.frame(distance_matrix, id.vars = "samples")
distance_matrix_melt$Comparision<-paste(distance_matrix_melt$samples, distance_matrix_melt$variable, sep = ".")
distance_matrix_melt_filt<-subset(distance_matrix_melt, Comparision %in% compAll_T)
row.names(distance_matrix_melt_filt)<-as.character(distance_matrix_melt_filt$variable)
distance_matrix_melt_filt_info<-merge(distance_matrix_melt_filt, samdf, by=0)
#Factor
distance_matrix_melt_filt_info$Transect <- factor(distance_matrix_melt_filt_info$Transect, levels = c(1,2,3), labels = c("1","2", "3"))
distance_matrix_melt_filt_info$Ecotype <- factor(distance_matrix_melt_filt_info$Ecotype, levels = c("Meadow","Alder zone","Spruce-Alder", "Spruce","Pine"), labels = c("Meadow","Alder","Spruce-Alder", "Spruce","Pine"))
#
sup2 <- ggplot(distance_matrix_melt_filt_info, aes(Ecotype, value, shape = Type)) +
  geom_jitter(shape=16, size = 5, position=position_jitter(0.2), color = "black", alpha = 0.7) +
  geom_text_repel(aes(label = User_ID), nudge_x = 0.02, size = 4.0, segment.alpha = 0.5) +
  theme_pubr(border = TRUE) +
  facet_grid(~Transect) +
  theme(axis.text=element_text(size=12), 
        axis.text.x = element_text(size = 12, hjust = 0.5), 
        axis.title.y = element_text(size = 12, hjust = 0.5),
        legend.text=element_text(size=12), 
        legend.title=element_text(size=0),
        legend.position="none",
        axis.title.x = element_text(size = 12), 
        strip.text.x = element_text(size = 12, face = "bold"),
        strip.text.y = element_text(size = 12, face = "bold")) +
  labs(x="Ecotype", y = "Jensen-Shannon Distance (JSD)") +
  ylim(0, 1) 
print(sup2)
```
* Beta Diversity Plot comparing the Replicates A and B.

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE}
##PCOA
##Relative Abundance

#Remove zeros
#ps4 = filter_taxa(pseq, function(x) sum(x > 10) > (0.8*length(x)), TRUE)

Plots <- transform_sample_counts(pseq, function(otu) otu/sum(otu))
#
expt = prune_taxa(names(sort(taxa_sums(Plots), TRUE)[1:1000]), Plots)
ord<- sqrt(phyloseq::distance(Plots,Type = "samples", "jsd"))
pcoa=ordinate(Plots, "PCoA", distance=ord)
#
expt@sam_data$Transect <- factor(expt@sam_data$Transect, levels = c(1,2,3), labels = c("1","2", "3"))
expt@sam_data$Ecotype <- factor(expt@sam_data$Ecotype, levels = c("Meadow","Alder zone","Spruce-Alder", "Spruce","Pine"), labels = c("Meadow","Alder","Spruce-Alder", "Spruce","Pine"))
ord_DataFrame <- plot_ordination(expt, pcoa, "samples", justDF ="TRUE")
#
ordplot2 <- (ordplot <- plot_ordination(expt, pcoa, "samples", color="Ecotype", shape = "Transect") + 
               geom_hline(yintercept = 0, linetype = 'dashed', alpha = 0.3) + 
               geom_vline(xintercept = 0, linetype = 'dashed', alpha = 0.3) +
               geom_point(size = 5, color = "grey") +
               geom_text_repel(aes(label = Type), nudge_x = 0.04, size = 3.0, segment.alpha = 0.5) +
               scale_shape_manual(values=c(23,21,24)) +
               theme_pubr(border = TRUE) +
               coord_fixed(ratio = 1) +
               theme(axis.text=element_text(size=14), 
                     axis.text.x = element_text(size = 12, hjust = 0.5), 
                     axis.title.y = element_text(size = 18),
                     legend.text=element_text(size=14), 
                     legend.title=element_text(size=0),
                     legend.position="bottom",
                     axis.title.x = element_text(size = 18), 
                     strip.text.x = element_text(size = 20, face = "bold"))) +
  scale_color_manual(values = cols_Ecotype)+
  labs(x="PCo1 [13.3%]", y = "PCo2 [9.4%]", element_text(face = "bold"))
ordplot2$layers <- ordplot2$layers[-1]
ordplot2 + 
  geom_point(data=ord_DataFrame, aes(x = Axis.1, y = Axis.2, fill =Ecotype, size = 4))  +
  scale_fill_manual(values = cols_Ecotype) 
```

```{r,echo=FALSE,include=FALSE, eval = FALSE}
#Removing replicates 
P_Plots <- subset_samples(pseq, Main_Analysis =="Yes")
```

Rarefaction
```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE, message=FALSE, warning=FALSE}
psdata = rarefy_even_depth(P_Plots)
plot(as(otu_table(psdata), 'vector'), as(otu_table(psdata), 'vector'))
rarecurve(t(otu_table(psdata)), step=50, cex=0.5)
rarecurve(t(otu_table(P_Plots)), step=50, cex=0.5)

```


## Main Analysis

* Alpha Diversity Plot - A.


```{r,echo=FALSE,include=FALSE}
#Alpha Diversity
P_Plots
reads_sample <- readcount(P_Plots)
# check for first 5 samples
reads_sample[1:5]
sample_data(P_Plots)$Reads_Sample <- reads_sample
#
#alpha_diversityb <- estimate_richness(P_Plots,  measures = c("Shannon", "Observed"))
alpha_diversityb <- estimate_richness(P_Plots,  measures = c("Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher"))
df2 <- data.frame(alpha_diversityb, sample_data(P_Plots))
df2$Transect <- factor(df2$Transect, levels = c(1,2,3), labels = c("1","2", "3")) #Keep 1,2,3
df2$Ecotype <- factor(df2$Ecotype, levels = c("Meadow","Alder zone","Spruce-Alder", "Spruce","Pine"), labels = c("Meadow","Alder","Spruce-Alder", "Spruce","Pine"))

```

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE}
##Plot measures
PY <- levels(df2$Ecotype) # get the variables
PY.pairs <- combn(seq_along(PY), 2, simplify = FALSE, FUN = function(i)PY[i])

dose.labs <- c("Richness", "Shannon")
names(dose.labs) <- c("Observed", "Shannon")
#Scale
scales <- list(
  scale_y_continuous(limits = c(0,500)
            ))

##
options(ggrepel.max.overlaps = Inf)
p <- df2 %>% 
  #gather(key = metric, value = value, c("Observed", "Shannon")) %>%
    gather(key = metric, value = value, c("Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher")) %>%

  #mutate(metric = factor(metric, levels = c("Observed", "Shannon"))) %>%
    mutate(metric = factor(metric, levels = c("Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher"))) %>%

  ggplot(aes(x = Ecotype, y = value, color = Ecotype)) + #,shape = Type
  geom_point(size = 5, color = "grey") +
  labs(x = "", y = "") +
  theme_pubr(border = TRUE) +
  scale_colour_manual(values = cols_Ecotype) +
  theme(legend.position="top") +
  theme(legend.title = element_blank()) +
  facet_nested(metric~Transect, labeller=labeller(metric = dose.labs), scales = "free") +
  facetted_pos_scales(y = scales) 
p + 
  geom_point(data=p$data, aes(x = Ecotype, y = value, fill =Ecotype, size = 4))  +
  scale_fill_manual(values = cols_Ecotype) 
#Rplot_AlphaDiversity_MainAnalysis
```
```{r}
#plot by mean
#tt <- aggregate(df2$Observed, list(df2$Transect, df2$Ecotype), FUN=mean)



H <- df2$Shannon
S1 <- df2$Observed
S <- log(S1)
evenness <- H/S

Shannon <- aggregate(df2$Shannon, list(df2$Transect, df2$Ecotype), FUN=mean)

Chao1 <- aggregate(df2$Chao1, list(df2$Transect, df2$Ecotype), FUN=mean)

se.chao1 <- aggregate(df2$se.chao1, list(df2$Transect, df2$Ecotype), FUN=mean)

ACE <- aggregate(df2$ACE, list(df2$Transect, df2$Ecotype), FUN=mean)

se.ACE <- aggregate(df2$se.ACE, list(df2$Transect, df2$Ecotype), FUN=mean)

Simpson <- aggregate(df2$Simpson, list(df2$Transect, df2$Ecotype), FUN=mean)

InvSimpson <- aggregate(df2$InvSimpson, list(df2$Transect, df2$Ecotype), FUN=mean)

Fisher <- aggregate(df2$Fisher, list(df2$Transect, df2$Ecotype), FUN=mean)

Observed <- aggregate(df2$Observed, list(df2$Transect, df2$Ecotype), FUN=mean)

tt <- df2 %>% 
  group_by(Transect,Ecotype) %>% 
  summarise (Observed = mean(Observed))

tt2 <- df2 %>% 
  group_by(Transect,Ecotype) %>% 
  summarise (Shannon = mean(Shannon))

#write.table(df2, "/Users/juliana/Documents/GitHub/SMS-6198-22-ITS/results/DF_Main_Data.tsv", sep='\t', row.names=FALSE, quote=FALSE)
```

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE}
PY <- levels(tt$Ecotype) # get the variables
PY.pairs <- combn(seq_along(PY), 2, simplify = FALSE, FUN = function(i)PY[i])

##
options(ggrepel.max.overlaps = Inf)
p4 <- tt %>% 
  ggplot(aes(x = Ecotype, y = Observed, color = Ecotype)) + #,shape = Type
  geom_point(size = 5, color = "grey") +
  labs(x = "", y = "") +
  theme_pubr(border = TRUE) +
  scale_colour_manual(values = cols_Ecotype) +
  theme(legend.position="top") +
  theme(legend.title = element_blank()) +
  facet_nested(~Transect) +
  stat_compare_means( method='wilcox.test', p.adjust.method = "BH", label = "p.signif", comparisons = PY.pairs, size = 2) 

p4 + 
  geom_point(data=p4$data, aes(x = Ecotype, y = Observed, fill =Ecotype, size = 4))  +
  scale_fill_manual(values = cols_Ecotype) 
```


```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE}
PY2 <- levels(tt$Ecotype) # get the variables
PY2.pairs <- combn(seq_along(PY2), 2, simplify = FALSE, FUN = function(i)PY2[i])

##
options(ggrepel.max.overlaps = Inf)
p5 <- tt %>% 
  ggplot(aes(x = Ecotype, y = Observed, color = Transect)) + #,shape = Type
  geom_point(size = 5, color = "grey") +
  labs(x = "", y = "") +
  theme_pubr(border = TRUE) +
  scale_colour_manual(values = cols_Transect) +
  theme(legend.position="top") +
  theme(legend.title = element_blank()) +
  stat_compare_means( method='anova', label = "p.signif", comparisons = PY2.pairs, size = 2) 

  #stat_compare_means( method='wilcox.test', p.adjust.method = "BH", label = "p.signif", comparisons = PY2.pairs, size = 2) 

p5 + 
  geom_point(data=p5$data, aes(x = Ecotype, y = Observed, fill =Transect, size = 4))  +
  scale_fill_manual(values = cols_Transect) 
```


```{r}
gpca  <- ordinate(Plots, "CCA")
# Scree plot
plot_scree(gpca, "Scree Plot for Global Patterns Correspondence Analysis")
```

* Beta Diversity Plot - A.

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE}
##Relative Abundance
GP = filter_taxa(P_Plots, function(x) sum(x > 3) > (0.2*length(x)), TRUE)
#Plots <- transform_sample_counts(pseq, function(otu) otu/sum(otu))

Plots <- transform_sample_counts(GP, function(otu) otu/sum(otu))
#
expt = prune_taxa(names(sort(taxa_sums(Plots), TRUE)[1:1000]), Plots)
ord<- sqrt(phyloseq::distance(Plots,Type = "samples", "jsd"))
pcoa=ordinate(Plots, "PCoA", distance=ord)
#
expt@sam_data$Transect <- factor(expt@sam_data$Transect, levels = c(1,2,3), labels = c("1","2", "3"))
expt@sam_data$Ecotype <- factor(expt@sam_data$Ecotype, levels = c("Meadow","Alder zone","Spruce-Alder", "Spruce","Pine"), labels = c("Meadow","Alder","Spruce-Alder", "Spruce","Pine"))
ord_DataFrame <- plot_ordination(expt, pcoa, "samples", justDF ="TRUE")
ordplot2 <- (ordplot <- plot_ordination(expt, pcoa, "samples", color="Ecotype", shape = "Transect") + 
               geom_hline(yintercept = 0, linetype = 'dashed', alpha = 0.3) + 
               geom_vline(xintercept = 0, linetype = 'dashed', alpha = 0.3) +
               geom_point(size = 5, color = "grey") +
               scale_shape_manual(values=c(23,21,24)) +
               theme_pubr(border = TRUE) +
               coord_fixed(ratio = 1) +
               theme(axis.text=element_text(size=14), 
                     axis.text.x = element_text(size = 12, hjust = 0.5), 
                     axis.title.y = element_text(size = 18),
                     legend.text=element_text(size=14), 
                     legend.title=element_text(size=0),
                     legend.position="bottom",
                     axis.title.x = element_text(size = 18), 
                     strip.text.x = element_text(size = 20, face = "bold"))) +
  scale_color_manual(values = cols_Ecotype)#+
  labs(x="PCo1 [13.3%]", y = "PCo2 [9.3%]", element_text(face = "bold"))
ordplot2$layers <- ordplot2$layers[-1]
ordplot2 + 
  geom_point(data=ord_DataFrame, aes(x = Axis.1, y = Axis.2, fill =Ecotype, size = 4))  +
  scale_fill_manual(values = cols_Ecotype) 
#Rplot_BetaDiversity_MainAnalysis
```


```{r}
#Vegam NMDS
# Set working directory
# Read in species matrix AND grouping variables
#Filter Data = zeros GP
island.spp <- data.frame(GP@otu_table)
island.spp_groups <-  data.frame(GP@sam_data)
  # This is our grouping data

# Calculating relative abundance and creating new dataframe with relative abundance data
island.spp.rel <-         
  decostand(island.spp, method = "total")

# Calculate distance matrix
island.spp_distmat <- 
  vegdist(island.spp.rel, method = "bray")

# Creating easy to view matrix and writing .csv
island.spp_distmat <- 
  as.matrix(island.spp_distmat, labels = T)
#write.csv(island.spp_distmat, "island_spp_distmat.csv")


island.spp_NMS <-
  metaMDS(island.spp_distmat,
          distance = "bray",
          k = 3,
          maxit = 999, 
          trymax = 500,
          wascores = TRUE)


# Shepards test/goodness of fit
goodness(island.spp_NMS) # Produces a results of test statistics for goodness of fit for each point

stressplot(island.spp_NMS) # Produces a Shepards diagram
```

```{r}
# Plotting points in ordination space
plot(island.spp_NMS, "sites")   # Produces distance 
orditorp(island.spp_NMS, "sites")   # Gives points labels
```



```{r}
#https://rpubs.com/CPEL/NMDS
plot(island.spp_NMS)
with(island.spp_groups,
     points(island.spp_NMS,
            display = "sites",
            color="Ecotype",
            #col = island.spp_groups$Ecotype,
            pch = cols_Ecotype[Ecotype],
            bg = cols_Transect[Transect]))
```

```{r}

GP1 = transform_sample_counts(GP, function(x) 1E6 * x/sum(x))
GP.ord <- ordinate(GP1, "NMDS", "bray")
p1 = plot_ordination(GP1, GP.ord, type="taxa", color="Phylum", title="taxa")
print(p1)
p1 + facet_wrap(~Phylum, 3)

GP1@sam_data$Transect <- factor(GP1@sam_data$Transect, levels = c(1,2,3), labels = c("1","2", "3"))

p2 = plot_ordination(GP1, GP.ord, type="samples", color="Ecotype", shape="Transect") 
p2 + geom_polygon(aes(fill=Ecotype)) + geom_point(size=5) + ggtitle("samples") +   
  scale_fill_manual(values = cols_Ecotype) +
  scale_color_manual(values = cols_Ecotype)

####
p3 = plot_ordination(GP1, GP.ord, type="biplot", color="Ecotype", shape="Phylum", title="biplot")
# Some stuff to modify the automatic shape scale
GP1.shape.names = get_taxa_unique(GP1, "Phylum")
GP1.shape <- 15:(15 + length(GP1.shape.names) - 1)
names(GP1.shape) <- GP1.shape.names
GP1.shape["samples"] <- 16
p3 + scale_shape_manual(values=GP1.shape)


p9 = plot_ordination(GP1, GP.ord, type="split", color="Ecotype", shape="Transect", title="split") 
p9

#####

dist = "bray"
#ord_meths = c("DCA", "CCA", "RDA", "DPCoA", "NMDS", "MDS", "PCoA")
ord_meths = c("CCA",  "NMDS", "MDS", "PCoA")

plist = llply(as.list(ord_meths), function(i, physeq, dist){
        ordi = ordinate(physeq, method=i, distance=dist)
        plot_ordination(physeq, ordi, "samples", color="Ecotype")
}, GP1, dist)

names(plist) <- ord_meths

pdataframe = ldply(plist, function(x){
    df = x$data[, 1:2]
    colnames(df) = c("Axis_1", "Axis_2")
    return(cbind(df, x$data))
})
names(pdataframe)[1] = "method"


p = ggplot(pdataframe, aes(Axis_1, Axis_2, color=Ecotype, shape=Transect, fill=Ecotype))
p = p + geom_point(size=4) + geom_polygon()
p = p + facet_wrap(~method, scales="free")
p = p + scale_fill_brewer(type="qual", palette="Set1")
p = p + scale_colour_brewer(type="qual", palette="Set1")
p

plist[[2]]
#NMDS elipse
#####

```


* Beta Diversity Plot - B.

```{r, fig.width = 14.5, fig.height = 7.58, echo=FALSE}
ordplot3 <- (ordplot <- plot_ordination(expt, pcoa, "samples", color="Ecotype") + 
               geom_hline(yintercept = 0, linetype = 'dashed', alpha = 0.3) + 
               geom_vline(xintercept = 0, linetype = 'dashed', alpha = 0.3) +
               geom_point(size = 5, color = "grey") +
               scale_shape_manual(values=c(23,21,24)) +
               theme_pubr(border = TRUE) +
               coord_fixed(ratio = 1) +
               theme(axis.text=element_text(size=14), 
                     axis.text.x = element_text(size = 12, hjust = 0.5), 
                     axis.title.y = element_text(size = 18),
                     legend.text=element_text(size=14), 
                     legend.title=element_text(size=0),
                     legend.position="bottom",
                     axis.title.x = element_text(size = 18), 
                     strip.text.x = element_text(size = 20, face = "bold"))) +
  scale_color_manual(values = cols_Ecotype)+
  labs(x="PCo1 [13.3%]", y = "PCo2 [9.3%]", element_text(face = "bold")) +
  facet_grid(~Transect)
ordplot3$layers <- ordplot3$layers[-1]
ordplot3 + 
  geom_point(data=ord_DataFrame, aes(x = Axis.1, y = Axis.2, fill =Ecotype, size = 4))  +
  scale_fill_manual(values = cols_Ecotype)
```
* Permutational analysis of variance

```{r, echo=FALSE}
metadata <- as(sample_data(P_Plots), "data.frame")
dist.bc <- sqrt(phyloseq::distance(P_Plots, method = "jsd"))
permanova <- adonis2(dist.bc ~ Ecotype + Transect, data = metadata, perm=9999)
permanova
```

* Relative abundance of the top 50 ASVs

```{r, fig.width = 20.5, fig.height = 12, echo=FALSE}
#PlotBar
phylo.relative <- transform_sample_counts(P_Plots, function(otu) otu/sum(otu))
#Subset
top <- names(sort(taxa_sums(phylo.relative), decreasing=TRUE))[1:20]
sample_data(phylo.relative)$Transect <- factor(sample_data(phylo.relative)$Transect, levels = c(1,2,3), labels = c("1","2", "3"))
sample_data(phylo.relative)$Ecotype <- factor(sample_data(phylo.relative)$Ecotype, levels = c("Meadow","Alder zone","Spruce-Alder", "Spruce","Pine"), labels = c("Meadow","Alder","Spruce-Alder", "Spruce","Pine"))
#
ps.top <- prune_taxa(top, phylo.relative)
meta <- data.frame(meta(ps.top))
Label <- rownames(meta)
sample_data(ps.top)$Label <- Label
meta <- data.frame(meta(ps.top))
taxonomy <- data.frame(tax_table(ps.top))
otu.relative <- data.frame(abundances(ps.top, "compositional"))
#
batch1_taxonomy_otu_metadata <- merge(taxonomy, otu.relative, by=0, all=TRUE)
#
batch1_media_melt <- melt(batch1_taxonomy_otu_metadata, id.vars=c("Row.names", "Kingdom","Phylum", "Class", "Order", "Family", "Genus","Species", "ASV_id","ASV", "taxa_name"))
colnames(batch1_media_melt) <- c("Row.names", "Kingdom","Phylum", "Class", "Order", "Family", "Genus","Species","ASV_id","ASV", "taxa_name","sample", "RA")
#
Batch1_taxa_all_metadata2 =  merge(batch1_media_melt, meta, by.x = "sample", by.y = "Label")
Batch1_taxa_all_metadata2 = Batch1_taxa_all_metadata2[!Batch1_taxa_all_metadata2$Genus =="Unknown",]
#
list_ <- data.frame(Batch1_taxa_all_metadata2 %>%
                      dplyr::group_by(Genus) %>%
                      dplyr::summarise(RA_count = sum(as.numeric(RA))) %>%
                      dplyr::arrange(desc(RA_count)))
list_sp <- list_$Genus
#
#Batch1_taxa_all_metadata2$Species <- factor(Batch1_taxa_all_metadata2$Species, levels = list_sp)
#Batch1_taxa_all_metadata2$taxa_name <- factor(Batch1_taxa_all_metadata2$taxa_name, levels = list_sp)
#Batch1_taxa_all_metadata2$Phylum <- factor(Batch1_taxa_all_metadata2$Phylum, levels = list_sp)
#Batch1_taxa_all_metadata2$Family <- factor(Batch1_taxa_all_metadata2$Family, levels = list_sp)
Batch1_taxa_all_metadata2$Genus <- factor(Batch1_taxa_all_metadata2$Genus, levels = list_sp)
##Changing the color

getPalette = colorRampPalette(brewer.pal(8, "Dark2"))
speciesList = unique(tax_table(ps.top)[,"Genus"])
speciesPalette = getPalette(length(speciesList))
names(speciesPalette) = speciesList
#Change for Species, Genus
ggplot(data=Batch1_taxa_all_metadata2, aes(x=Ecotype, group = Genus)) +
  geom_bar(aes(y=RA, fill = Genus),stat="identity", alpha=.7) + 
  theme_pubr(border = TRUE) +
  theme(axis.text.x = element_text(size = 14, hjust = 0.5), 
        axis.text.y = element_text(size = 14, hjust = 1),
        axis.title.x.bottom = element_text(size = 18),
        axis.title.y = element_text(size = 18),
        legend.position = "bottom") +
  scale_fill_manual(values= speciesPalette) +
  facet_grid(~Transect, scales = "free", space = "free")



ggplot(data=Batch1_taxa_all_metadata2, aes(x=Ecotype, group = Genus)) +
  geom_bar(aes(y=RA, fill = Genus),stat="identity", alpha=.7) + 
  theme_pubr(border = TRUE) +
  theme(axis.text.x = element_text(size = 14, hjust = 0.5), 
        axis.text.y = element_text(size = 14, hjust = 1),
        axis.title.x.bottom = element_text(size = 18),
        axis.title.y = element_text(size = 18),
        legend.position = "bottom") +
  scale_fill_manual(values= speciesPalette) +
  facet(~Transect)
#Rplot_PlotBar_ASVs
```

```{r}
#Heatmap with Deseq2
```



# Summary

Help is needed with running the "nfcore/ampliseq" pipeline developed
at NGI for the analyses of fungal ITS1 amplicons, Illumina Miseq
analysis NGI project ID P5953 (M.Hogberg_17_01_project summary from
2018-01-19 by Chuan Wang refers to P9723, >=Q30 (mean(SD), 70(2) (%),
Sum Reads=15 650 000, Mean reads per sample 171 711, 1 pool of
amplicons, 1 flowcell v3, PE 2x301bp (validated method),
demultiplexing, quality control and raw data delivery on Uppmax
(validated method). Agreement number M.Hogberg_16_01-20160826. Grus
delivery project delivery 00654. Because my support application
2019-01-17 was rejected, I have collaborated with partners in US on
this matter but all is extremely delayed for known reasons. I got some
hope today when I read about the recently developed pipeline for
fungal analyses! Unfortunately, I have no programming skills but have
a BSc in Molecular Biology.

Short summary of the work.  

# Further Work  

Further steps to be taken (if needed).

# References

Relevant references for methods, tools etc.

# Deliverables  

Files delivered to the user with descriptions.

## Directory  

```sh
/data/processed/b/

8 directories, 18 files
```

Total size is XX GB.

# Timeline

# Practical Info  
## Data responsibility

The responsibility for data archiving lies with the PI of the project. We do not offer long-term storage or retrieval of data.

+ __NBIS & Uppnex: __ We kindly ask that you remove the files from UPPMAX/UPPNEX. The main storage at UPPNEX is optimized for high-speed and parallel access, which makes it expensive and not the right place for longer time archiving. Please consider others by not taking up the expensive space. Please note that UPPMAX is a resource separate from the Bioinformatics Platform, administered by the Swedish National Infrastructure for Computing (SNIC) and SNIC-specifc project rules apply to all projects hosted at UPPMAX.   
+ __Sensitive data :__ Please note that special considerations may apply to the human-derived legally considered sensitive personal data. These should be handled according to specific laws and regulations as outlined e.g. [here](http://nbis.se/support/human-data.html).  
+ __Long-term backup :__ We recommend asking your local IT for support with long-term data archiving. Also a newly established [Data Office](https://www.scilifelab.se/data/) at SciLifeLab may be of help to discuss other options.  

## Acknowledgments

If you are presenting the results in a paper, at a workshop or conference, we kindly ask you to acknowledge us.

+ __NBIS staff__ are encouraged to be co-authors when this is merited in accordance to the ethical recommendations for authorship, e.g. [ICMJE recommendations](http://www.icmje.org/recommendations/browse/roles-and-responsibilities/defining-the-role-of-authors-and-contributors.html). If applicable, please include __Juliana, Assis Geraldo, National Bioinformatics Infrastructure Sweden, Science for Life Laboratory, NBIS__, as co-author. In other cases, NBIS would be grateful if support by us is acknowledged in publications according to this example:

> "Support by NBIS (National Bioinformatics Infrastructure Sweden) is gratefully acknowledged."

+ __UPPMAX__ kindly asks you to [acknowledge UPPMAX and SNIC](https://www.uppmax.uu.se/support/faq/general-miscellaneous-faq/acknowledging-uppmax--snic--and-uppnex/). If applicable, please add:

> "The computations were performed on resources provided by SNIC through Uppsala Multidisciplinary Center for Advanced Computational Science (UPPMAX) under Project SNIC 2022-22-352."

+ __NGI :__ For publications based on data from NGI Sweden, NGI, SciLifeLab and UPPMAX should be [acknowledged](https://ngisweden.scilifelab.se/info/faq#how-do-i-acknowledge-ngi-in-my-publication) like so:  

> "The authors would like to acknowledge support from Science for Life Laboratory (SciLifeLab), the National Genomics Infrastructure (NGI), and Uppsala Multidisciplinary Center for Advanced Computational Science (UPPMAX) for providing assistance in massive parallel sequencing and computational infrastructure."

# Support Completion  

You should soon be contacted by one of our managers with a request to close down the project in our internal system and for invoicing matters. If we do not hear from you within 30 days the project will be automatically closed and invoice sent. Again, we would like to remind you about data responsibility and acknowledgements, see sections: **Data Responsibility** and **Acknowledgments**.

You are welcome to come back to us with further data analysis request at any time via http://nbis.se/support/support.html.

Thank you for using NBIS.
